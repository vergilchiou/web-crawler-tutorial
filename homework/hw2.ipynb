{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "resp = requests.get('http://blog.castman.net/web-crawler-tutorial/ch2/blog/blog.html')\n",
    "soup = BeautifulSoup(resp.text, 'html.parser')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 右鍵 $\\rightarrow$ 檢查\n",
    "# 發現標題都在 h4 的標籤內"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Mac使用者'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find('h4').a.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 找到所有的 h4標籤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mac使用者\n",
      "給初學者的 Python 網頁爬蟲與資料分析\n",
      "給初學者的 Python 網頁爬蟲與資料分析\n",
      "給初學者的 Python 網頁爬蟲與資料分析\n",
      "給初學者的 Python 網頁爬蟲與資料分析\n",
      "給初學者的 Python 網頁爬蟲與資料分析\n"
     ]
    }
   ],
   "source": [
    "main_title = soup.find_all('h4')\n",
    "for title in main_title:\n",
    "    print(title.a.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 只要 h4裡面的 class = 'card-title'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mac使用者\n",
      "給初學者的 Python 網頁爬蟲與資料分析\n",
      "給初學者的 Python 網頁爬蟲與資料分析\n",
      "給初學者的 Python 網頁爬蟲與資料分析\n",
      "給初學者的 Python 網頁爬蟲與資料分析\n",
      "給初學者的 Python 網頁爬蟲與資料分析\n"
     ]
    }
   ],
   "source": [
    "main_title = soup.find_all('h4', 'card-title')\n",
    "for title in main_title:\n",
    "    print(title.a.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "等同於以下寫法\n",
    "```\n",
    "soup.find_all('h4', 'card-title')\n",
    "soup.find_all('h4', {'class'='card-title'})\n",
    "soup.find_all('h4', class_ = 'card-title')\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 若只是要找出所有 class = 'card-title'的元件\n",
    "# 則第一個變數字串留白即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<h4 class=\"card-title\">\n",
       " <a href=\"http://www.pycone.com/blogs#pablo\">Mac使用者</a>\n",
       " </h4>, <h4 class=\"card-title\">\n",
       " <a href=\"http://www.pycone.com/blogs#pablo\">給初學者的 Python 網頁爬蟲與資料分析</a>\n",
       " </h4>, <h4 class=\"card-title\">\n",
       " <a href=\"http://www.pycone.com/blogs#pablo\">給初學者的 Python 網頁爬蟲與資料分析</a>\n",
       " </h4>, <h4 class=\"card-title\">\n",
       " <a href=\"http://www.pycone.com/blogs#pablo\">給初學者的 Python 網頁爬蟲與資料分析</a>\n",
       " </h4>, <h4 class=\"card-title\">\n",
       " <a href=\"http://www.pycone.com/blogs#pablo\">給初學者的 Python 網頁爬蟲與資料分析</a>\n",
       " </h4>, <h4 class=\"card-title\">\n",
       " <a href=\"http://www.pycone.com/blogs#pablo\">給初學者的 Python 網頁爬蟲與資料分析</a>\n",
       " </h4>]"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all('', 'card-title')\n",
    "# key = value 的方式\n",
    "# soup.find_all(class_='card-title')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# key=value 的方式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'在Mac環境下安裝Python與Sublime Text3 Read More'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find(id='mac-p').text.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "但若是 key有特殊符號則會錯誤  \n",
    "例如：  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "keyword can't be an expression (<ipython-input-61-b6fdbb0f9ae1>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-61-b6fdbb0f9ae1>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    soup.find(data-foo = \"mac-foo\")\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m keyword can't be an expression\n"
     ]
    }
   ],
   "source": [
    "soup.find(data-foo = \"mac-foo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "此時改用\n",
    "```\n",
    "soup.find_all('', {'data-foo'='mac-foo'})\n",
    "```\n",
    "即可"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 取得個篇blog所有的文字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['開發環境設定', 'Mac使用者', '在Mac環境下安裝Python與Sublime Text3', 'Read More']\n",
      "['資料科學', '給初學者的 Python 網頁爬蟲與資料分析', '(1) 前言', 'Read More']\n",
      "['資料科學', '給初學者的 Python 網頁爬蟲與資料分析', '(2) 套件安裝與啟動網頁爬蟲', 'Read More']\n",
      "['資料科學', '給初學者的 Python 網頁爬蟲與資料分析', '(3) 解構並擷取網頁資料', 'Read More']\n",
      "['資料科學', '給初學者的 Python 網頁爬蟲與資料分析', '(4) 擷取資料及下載圖片', 'Read More']\n",
      "['資料科學', '給初學者的 Python 網頁爬蟲與資料分析', '(5) 資料分析及展示', 'Read More']\n"
     ]
    }
   ],
   "source": [
    "divs = soup.find_all('div', class_= 'content')\n",
    "for div in divs:\n",
    "    # print(div) # 很亂\n",
    "    # print(div.h6.text.strip(), div.h4.a.text.strip(), div.p.text.strip()) # 麻煩\n",
    "    print(list(div.stripped_strings)) # div.stripped_strings 回傳的是 iterator物件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
